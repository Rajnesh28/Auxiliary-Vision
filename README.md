# StormHacks2022

**Overview:**

Our app aims to help support the millions of people around the globe with visual impairments using computer vision and machine learning APIs from Google Cloud Providers. Using a Flask framework, we take our naturally simplistic user interface and use photos taken from the smartphone, which sends photos to our Python backend to process and provide the user with TTS characteristics of the image. Also, to help support students with accessibility issues to learning, they can upload a pdf file and it can be read out loud.  


As of now, we are able to analyze in the back-end
- Objects in images
- Text in images
- Text in PDF files

**Tech Stack:**

- Google Cloud Vision API
- Google Text-to-Speech API
- Python

    Some External Libraries:
    - PDF2Image
    - Poppler PDF Rendering library

- Flask
- React Native (JavaScript)

**Plan Forward:**

Aiming to connect the current back end python server with the front end React Native app.

![Logo](/images/ReactAppLogo.png)
